{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "class SmartLeaf(object):\n",
    "    \"\"\"\n",
    "    Smart leaf that holds the naive bayes model trained on the instances that got to it during training.\n",
    "    Not that it doesnt saves the instances themselves\n",
    "    \"\"\"\n",
    "    def __init__(self, leaf_id, X, y):\n",
    "        self._leaf_id = leaf_id\n",
    "        self.model = self._add_naive_bayes_model(X, y)\n",
    "    def _add_naive_bayes_model(self, X, y):\n",
    "        naive_bayes_model = GaussianNB()\n",
    "        return naive_bayes_model.fit(X, y.ravel())\n",
    "    \n",
    "class BetterTree(DecisionTreeClassifier):\n",
    "    \"\"\"\n",
    "    A tree that creates a naive bayes model in each of its leaves out of the instances that got there during\n",
    "    training.\n",
    "    The prediction on the leaf is done using this model\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 criterion=\"gini\",\n",
    "                 splitter=\"best\",\n",
    "                 max_depth=None,\n",
    "                 min_samples_split=2,\n",
    "                 min_samples_leaf=1,\n",
    "                 min_weight_fraction_leaf=0.,\n",
    "                 max_features=None,\n",
    "                 random_state=None,\n",
    "                 max_leaf_nodes=None,\n",
    "                 min_impurity_decrease=0.,\n",
    "                 min_impurity_split=None,\n",
    "                 class_weight=None,\n",
    "                 presort=False):\n",
    "        super(BetterTree, self).__init__(\n",
    "            criterion=criterion,\n",
    "            splitter=splitter,\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "            max_features=max_features,\n",
    "            max_leaf_nodes=max_leaf_nodes,\n",
    "            class_weight=class_weight,\n",
    "            random_state=random_state,\n",
    "            min_impurity_decrease=min_impurity_decrease,\n",
    "            min_impurity_split=min_impurity_split,\n",
    "            presort=presort)\n",
    "        self._leaves = {}\n",
    "    def fit(self, X, y, sample_weight=None, check_input=True, X_idx_sorted=None):\n",
    "        # Create the tree as usual\n",
    "        super(BetterTree, self).fit(\n",
    "            X, y,\n",
    "            sample_weight=sample_weight,\n",
    "            check_input=check_input,\n",
    "            X_idx_sorted=X_idx_sorted)\n",
    "         # Find the leaves each training instance reached\n",
    "        leaves = self.tree_.apply(X)\n",
    "        leaf_to_instances = defaultdict(list)\n",
    "        for instance_index, leaf in enumerate(leaves):\n",
    "            leaf_to_instances[leaf].append(instance_index)\n",
    "         # For each leaf, create SmartLeaf object which hold the naive bayes model trained on the instances that\n",
    "        # reached this leaf and save it in the tree state.\n",
    "        for leaf_index, instance_indexes in leaf_to_instances.items():\n",
    "            self._leaves[leaf_index] = SmartLeaf(leaf_index, X[instance_indexes,], y[instance_indexes])\n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, X, check_input=True):\n",
    "        \"\"\"\n",
    "        Override the original predict_proba by simply calling the relevant naive bayes predict_proba\n",
    "        \"\"\"\n",
    "        X = self._validate_X_predict(X, check_input)\n",
    "         # Find the leaf each instance reach\n",
    "        leaf_indexes = self.apply(X)\n",
    "         # Create placeholder matrix for the result\n",
    "        results = np.zeros(shape=(X.shape[0], self.n_classes_))\n",
    "         # For each instance call naive bayes predict_proba of the matching leaf and insert to result.\n",
    "        for instance_index, leaf_index in enumerate(leaf_indexes):\n",
    "            results[instance_index] = self._leaves[leaf_index].model.predict_proba([X[instance_index]])\n",
    "        return results\n",
    "    \n",
    "class BetterForest(RandomForestClassifier):\n",
    "    \"\"\"\n",
    "    A Random Forest model that uses BetterTree\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 n_estimators='warn',\n",
    "                 criterion=\"gini\",\n",
    "                 max_depth=None,\n",
    "                 min_samples_split=2,\n",
    "                 min_samples_leaf=1,\n",
    "                 min_weight_fraction_leaf=0.,\n",
    "                 max_features=\"auto\",\n",
    "                 max_leaf_nodes=None,\n",
    "                 min_impurity_decrease=0.,\n",
    "                 min_impurity_split=None,\n",
    "                 bootstrap=True,\n",
    "                 oob_score=False,\n",
    "                 n_jobs=None,\n",
    "                 random_state=None,\n",
    "                 verbose=0,\n",
    "                 warm_start=False,\n",
    "                 class_weight=None):\n",
    "        super(RandomForestClassifier, self).__init__(\n",
    "            base_estimator=BetterTree(),\n",
    "            n_estimators=n_estimators,\n",
    "            estimator_params=(\"criterion\", \"max_depth\", \"min_samples_split\",\n",
    "                              \"min_samples_leaf\", \"min_weight_fraction_leaf\",\n",
    "                              \"max_features\", \"max_leaf_nodes\",\n",
    "                              \"min_impurity_decrease\", \"min_impurity_split\",\n",
    "                              \"random_state\"),\n",
    "            bootstrap=bootstrap,\n",
    "            oob_score=oob_score,\n",
    "            n_jobs=n_jobs,\n",
    "            random_state=random_state,\n",
    "            verbose=verbose,\n",
    "            warm_start=warm_start,\n",
    "            class_weight=class_weight)\n",
    "        self.criterion = criterion\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.min_weight_fraction_leaf = min_weight_fraction_leaf\n",
    "        self.max_features = max_features\n",
    "        self.max_leaf_nodes = max_leaf_nodes\n",
    "        self.min_impurity_decrease = min_impurity_decrease\n",
    "        self.min_impurity_split = min_impurity_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BetterForest(bootstrap=True, class_weight=None, criterion='gini', max_depth=6,\n",
       "       max_features=8, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "       min_impurity_split=None, min_samples_leaf=1, min_samples_split=2,\n",
       "       min_weight_fraction_leaf=0.0, n_estimators=2, n_jobs=1,\n",
       "       oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=16,\n",
    "                           n_informative=8, n_redundant=0,\n",
    "                           random_state=0, shuffle=False)\n",
    "clf = BetterForest(n_estimators=2, max_depth=6, random_state=0, max_features=8, n_jobs=1)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.13272398 0.21496327 0.06225088 0.02529811 0.1734036  0.02215507\n",
      " 0.05087502 0.24057609 0.005743   0.01205432 0.00778437 0.00370332\n",
      " 0.01586887 0.01070866 0.01043189 0.01145953]\n"
     ]
    }
   ],
   "source": [
    "print(clf.feature_importances_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict([[0, 1, 0, 0, 2, 0, 0, 0, 3, 0, 0, 0, 0, 0, 2, 0]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
