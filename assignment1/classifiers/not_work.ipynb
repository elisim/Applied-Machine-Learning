{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class NaiveBayesLeaf(object):\n",
    "    \"\"\"\n",
    "    Holds a naive bayes model.\n",
    "    \"\"\"\n",
    "    def __init__(self, leaf_id, X, y):\n",
    "        self._leaf_id = leaf_id\n",
    "        self.model = self._add_naive_bayes_model(X, y)\n",
    "    def _add_naive_bayes_model(self, X, y):\n",
    "        naive_bayes_model = GaussianNB()\n",
    "        return naive_bayes_model.fit(X, y.ravel())\n",
    "\n",
    "class NaiveBayesModelTree(DecisionTreeClassifier):\n",
    "    \"\"\"\n",
    "     Decision tree classifier model with a naive bayes model in the leaves. \n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                criterion=\"gini\",\n",
    "                splitter=\"best\",\n",
    "                max_depth=None,\n",
    "                min_samples_split=2,\n",
    "                min_samples_leaf=1,\n",
    "                min_weight_fraction_leaf=0.,\n",
    "                max_features=None,\n",
    "                random_state=None,\n",
    "                max_leaf_nodes=None,\n",
    "                min_impurity_decrease=0.,\n",
    "                min_impurity_split=None,\n",
    "                class_weight=None,\n",
    "                presort=False):\n",
    "        super().__init__(\n",
    "            criterion=criterion,\n",
    "            splitter=splitter,\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "            max_features=max_features,\n",
    "            max_leaf_nodes=max_leaf_nodes,\n",
    "            class_weight=class_weight,\n",
    "            random_state=random_state,\n",
    "            min_impurity_decrease=min_impurity_decrease,\n",
    "            min_impurity_split=min_impurity_split,\n",
    "            presort=presort)\n",
    "        self.__leaves = {}\n",
    "\n",
    "    def fit(self, X, y, sample_weight=None, check_input=True, X_idx_sorted=None):\n",
    "        super().fit(X, y,\n",
    "                    sample_weight=sample_weight,\n",
    "                    check_input=check_input,\n",
    "                    X_idx_sorted=X_idx_sorted)\n",
    "        \n",
    "        leaves = self.tree_.apply(X)\n",
    "        leaf_to_instances = defaultdict(list)\n",
    "        for instance_index, leaf in enumerate(leaves):\n",
    "            leaf_to_instances[leaf].append(instance_index)\n",
    "        # For each leaf, create SmartLeaf object which hold the naive bayes model trained on the instances that\n",
    "        # reached this leaf and save it in the tree state.\n",
    "        for leaf_index, instance_indexes in leaf_to_instances.items():\n",
    "            self._leaves[leaf_index] = SmartLeaf(leaf_index, X[instance_indexes,], y[instance_indexes])\n",
    "        return self\n",
    "        \n",
    "    def predict_proba():\n",
    "        \"\"\"\n",
    "        Override the original predict_proba by simply calling the relevant naive bayes predict_proba\n",
    "        \"\"\"\n",
    "        X = self._validate_X_predict(X, check_input)\n",
    "         # Find the leaf each instance reach\n",
    "        leaf_indexes = self.apply(X)\n",
    "         # Create placeholder matrix for the result\n",
    "        results = np.zeros(shape=(X.shape[0], self.n_classes_))\n",
    "         # For each instance call naive bayes predict_proba of the matching leaf and insert to result.\n",
    "        for instance_index, leaf_index in enumerate(leaf_indexes):\n",
    "            results[instance_index] = self._leaves[leaf_index].model.predict_proba([X[instance_index]])\n",
    "        return results\n",
    "    \n",
    "class BetterForest(RandomForestClassifier):\n",
    "    \"\"\"\n",
    "    A Random Forest model that uses BetterTree\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 n_estimators='warn',\n",
    "                 criterion=\"gini\",\n",
    "                 max_depth=None,\n",
    "                 min_samples_split=2,\n",
    "                 min_samples_leaf=1,\n",
    "                 min_weight_fraction_leaf=0.,\n",
    "                 max_features=\"auto\",\n",
    "                 max_leaf_nodes=None,\n",
    "                 min_impurity_decrease=0.,\n",
    "                 min_impurity_split=None,\n",
    "                 bootstrap=True,\n",
    "                 oob_score=False,\n",
    "                 n_jobs=None,\n",
    "                 random_state=None,\n",
    "                 verbose=0,\n",
    "                 warm_start=False,\n",
    "                 class_weight=None):\n",
    "        super().__init__(\n",
    "            base_estimator=NaiveBayesModelTree(),\n",
    "            n_estimators=n_estimators,\n",
    "            estimator_params=(\"criterion\", \"max_depth\", \"min_samples_split\",\n",
    "                              \"min_samples_leaf\", \"min_weight_fraction_leaf\",\n",
    "                              \"max_features\", \"max_leaf_nodes\",\n",
    "                              \"min_impurity_decrease\", \"min_impurity_split\",\n",
    "                              \"random_state\"),\n",
    "            bootstrap=bootstrap,\n",
    "            oob_score=oob_score,\n",
    "            n_jobs=n_jobs,\n",
    "            random_state=random_state,\n",
    "            verbose=verbose,\n",
    "            warm_start=warm_start,\n",
    "            class_weight=class_weight)\n",
    "        self.criterion = criterion\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.min_weight_fraction_leaf = min_weight_fraction_leaf\n",
    "        self.max_features = max_features\n",
    "        self.max_leaf_nodes = max_leaf_nodes\n",
    "        self.min_impurity_decrease = min_impurity_decrease\n",
    "        self.min_impurity_split = min_impurity_split\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'base_estimator'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-a64ff5fe830c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m                            \u001b[0mn_informative\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_redundant\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                            random_state=0, shuffle=False)\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBetterForest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-c0d5d4992f9f>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, n_estimators, criterion, max_depth, min_samples_split, min_samples_leaf, min_weight_fraction_leaf, max_features, max_leaf_nodes, min_impurity_decrease, min_impurity_split, bootstrap, oob_score, n_jobs, random_state, verbose, warm_start, class_weight)\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[0mwarm_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarm_start\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_depth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'base_estimator'"
     ]
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=16,\n",
    "                           n_informative=8, n_redundant=0,\n",
    "                           random_state=0, shuffle=False)\n",
    "clf = BetterForest(n_estimators=2, max_depth=6, random_state=0, max_features=8)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
